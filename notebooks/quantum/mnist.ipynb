{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digits (Quantum)\n",
    "\n",
    "This notebooks trains and evaluates quantum vision transformers for the MNIST Digits classification task.\n",
    "You can find information about the dataset at https://www.tensorflow.org/datasets/catalog/mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:09:15.390864Z",
     "iopub.status.busy": "2023-10-09T22:09:15.390733Z",
     "iopub.status.idle": "2023-10-09T22:09:23.172591Z",
     "shell.execute_reply": "2023-10-09T22:09:23.172152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "from quantum_transformers.utils import plot_image\n",
    "from quantum_transformers.datasets import get_mnist_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import VisionTransformer\n",
    "from quantum_transformers.quantum_layer import get_circuit\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are trained using the following devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:09:23.174932Z",
     "iopub.status.busy": "2023-10-09T22:09:23.174578Z",
     "iopub.status.idle": "2023-10-09T22:09:23.381262Z",
     "shell.execute_reply": "2023-10-09T22:09:23.380801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRT_CPU_0 cpu\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many samples the dataset has, the shape of the input data, and how one sample looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:09:23.382956Z",
     "iopub.status.busy": "2023-10-09T22:09:23.382812Z",
     "iopub.status.idle": "2023-10-09T22:09:23.937202Z",
     "shell.execute_reply": "2023-10-09T22:09:23.936769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 18:16:01.092563: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /global/cfs/cdirs/m4392/salcc/data/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/global'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mnist_train_dataloader, mnist_valid_dataloader, mnist_test_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mget_mnist_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m first_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(mnist_train_dataloader))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(first_image\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Downloads/isef-23-24/quantum_transformers/datasets.py:118\u001b[0m, in \u001b[0;36mget_mnist_dataloaders\u001b[0;34m(data_dir, batch_size, drop_remainder)\u001b[0m\n\u001b[1;32m    115\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(data_dir)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain[:90\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain[90\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m:]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_supervised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mwith_options(options), val_dataset\u001b[38;5;241m.\u001b[39mwith_options(options), test_dataset\u001b[38;5;241m.\u001b[39mwith_options(options)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCardinalities (train, val, test):\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_dataset\u001b[38;5;241m.\u001b[39mcardinality()\u001b[38;5;241m.\u001b[39mnumpy(), val_dataset\u001b[38;5;241m.\u001b[39mcardinality()\u001b[38;5;241m.\u001b[39mnumpy(), test_dataset\u001b[38;5;241m.\u001b[39mcardinality()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/tensorflow_datasets/core/logging/__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/tensorflow_datasets/core/load.py:649\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m`tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    643\u001b[0m dbuilder \u001b[38;5;241m=\u001b[39m _fetch_builder(\n\u001b[1;32m    644\u001b[0m     name,\n\u001b[1;32m    645\u001b[0m     data_dir,\n\u001b[1;32m    646\u001b[0m     builder_kwargs,\n\u001b[1;32m    647\u001b[0m     try_gcs,\n\u001b[1;32m    648\u001b[0m )\n\u001b[0;32m--> 649\u001b[0m \u001b[43m_download_and_prepare_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m   as_dataset_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/tensorflow_datasets/core/load.py:508\u001b[0m, in \u001b[0;36m_download_and_prepare_builder\u001b[0;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m    507\u001b[0m   download_and_prepare_kwargs \u001b[38;5;241m=\u001b[39m download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 508\u001b[0m   \u001b[43mdbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/tensorflow_datasets/core/logging/__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builder.py:653\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    644\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough disk space. Needed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (download: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, generated: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    645\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    649\u001b[0m       )\n\u001b[1;32m    650\u001b[0m   )\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_download_bytes()\n\u001b[0;32m--> 653\u001b[0m dl_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_download_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# Maybe save the `builder_cls` metadata common to all builder configs.\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBUILDER_CONFIGS:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builder.py:1204\u001b[0m, in \u001b[0;36mDatasetBuilder._make_download_manager\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1188\u001b[0m     max_simultaneous_downloads\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_SIMULTANEOUS_DOWNLOADS\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_SIMULTANEOUS_DOWNLOADS \u001b[38;5;241m<\u001b[39m max_simultaneous_downloads\n\u001b[1;32m   1191\u001b[0m ):\n\u001b[1;32m   1192\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1193\u001b[0m       (\n\u001b[1;32m   1194\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m sets `MAX_SIMULTANEOUS_DOWNLOADS`=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. The\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1201\u001b[0m       download_config\u001b[38;5;241m.\u001b[39moverride_max_simultaneous_downloads,\n\u001b[1;32m   1202\u001b[0m   )\n\u001b[0;32m-> 1204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdownload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDownloadManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanual_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanual_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanual_dir_instructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMANUAL_DOWNLOAD_INSTRUCTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFORCE_REDOWNLOAD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_extraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFORCE_REDOWNLOAD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_checksums_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_checksums_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregister_checksums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_checksums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregister_checksums_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregister_checksums_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_ssl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_ssl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_simultaneous_downloads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_simultaneous_downloads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/tensorflow_datasets/core/download/download_manager.py:255\u001b[0m, in \u001b[0;36mDownloadManager.__init__\u001b[0;34m(self, download_dir, extract_dir, manual_dir, manual_dir_instructions, url_infos, dataset_name, force_download, force_extraction, force_checksums_validation, register_checksums, register_checksums_path, verify_ssl, max_simultaneous_downloads)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manual_dir: Optional[epath\u001b[38;5;241m.\u001b[39mPath] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    252\u001b[0m     manual_dir  \u001b[38;5;66;03m# pytype: disable=annotation-type-mismatch  # attribute-variable-annotations\u001b[39;00m\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manual_dir_instructions \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdedent(manual_dir_instructions)\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_download \u001b[38;5;241m=\u001b[39m force_download\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/etils/epath/gpath.py:203\u001b[0m, in \u001b[0;36m_GPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new directory at this given path.\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parents:\n\u001b[0;32m--> 203\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_str, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/quantum-transformers-tX3w6yAK-py3.11/lib/python3.11/site-packages/etils/epath/backend.py:169\u001b[0m, in \u001b[0;36m_OsPathBackend.makedirs\u001b[0;34m(self, path, exist_ok, mode)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmakedirs\u001b[39m(\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    163\u001b[0m     path: PathLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     mode: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m   mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0o777\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m mode\n\u001b[0;32m--> 169\u001b[0m   \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/global'"
     ]
    }
   ],
   "source": [
    "mnist_train_dataloader, mnist_valid_dataloader, mnist_test_dataloader = get_mnist_dataloaders(batch_size=64, data_dir=data_dir)\n",
    "first_image = next(iter(mnist_train_dataloader))[0][0]\n",
    "print(first_image.shape)\n",
    "plot_image(first_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the quantum vision transformer on the best hyperparameters found using random hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:09:23.939000Z",
     "iopub.status.busy": "2023-10-09T22:09:23.938737Z",
     "iopub.status.idle": "2023-10-09T22:15:17.805879Z",
     "shell.execute_reply": "2023-10-09T22:15:17.805358Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:09:25.510151: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters = 1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 843/843 [00:46<00:00, 18.32batch/s, Loss = 1.8906, AUC = 79.17%] \n",
      "Epoch   2/30: 100%|██████████| 843/843 [00:10<00:00, 83.93batch/s, Loss = 1.4022, AUC = 92.00%] \n",
      "Epoch   3/30: 100%|██████████| 843/843 [00:09<00:00, 85.68batch/s, Loss = 0.9424, AUC = 95.62%] \n",
      "Epoch   4/30: 100%|██████████| 843/843 [00:10<00:00, 82.76batch/s, Loss = 0.7218, AUC = 96.88%] \n",
      "Epoch   5/30: 100%|██████████| 843/843 [00:10<00:00, 83.92batch/s, Loss = 0.6324, AUC = 97.40%] \n",
      "Epoch   6/30: 100%|██████████| 843/843 [00:10<00:00, 82.51batch/s, Loss = 0.5749, AUC = 97.80%] \n",
      "Epoch   7/30: 100%|██████████| 843/843 [00:10<00:00, 82.99batch/s, Loss = 0.5245, AUC = 98.17%] \n",
      "Epoch   8/30: 100%|██████████| 843/843 [00:09<00:00, 85.52batch/s, Loss = 0.4905, AUC = 98.38%] \n",
      "Epoch   9/30: 100%|██████████| 843/843 [00:10<00:00, 84.11batch/s, Loss = 0.4669, AUC = 98.53%] \n",
      "Epoch  10/30: 100%|██████████| 843/843 [00:10<00:00, 84.09batch/s, Loss = 0.4496, AUC = 98.60%] \n",
      "Epoch  11/30: 100%|██████████| 843/843 [00:10<00:00, 83.29batch/s, Loss = 0.4401, AUC = 98.66%] \n",
      "Epoch  12/30: 100%|██████████| 843/843 [00:10<00:00, 83.55batch/s, Loss = 0.4298, AUC = 98.71%] \n",
      "Epoch  13/30: 100%|██████████| 843/843 [00:10<00:00, 82.63batch/s, Loss = 0.4252, AUC = 98.71%] \n",
      "Epoch  14/30: 100%|██████████| 843/843 [00:09<00:00, 84.73batch/s, Loss = 0.4245, AUC = 98.73%] \n",
      "Epoch  15/30: 100%|██████████| 843/843 [00:10<00:00, 83.83batch/s, Loss = 0.4202, AUC = 98.74%] \n",
      "Epoch  16/30: 100%|██████████| 843/843 [00:10<00:00, 83.32batch/s, Loss = 0.4198, AUC = 98.74%] \n",
      "Epoch  17/30: 100%|██████████| 843/843 [00:10<00:00, 83.81batch/s, Loss = 0.4129, AUC = 98.78%] \n",
      "Epoch  18/30: 100%|██████████| 843/843 [00:10<00:00, 84.02batch/s, Loss = 0.4110, AUC = 98.79%] \n",
      "Epoch  19/30: 100%|██████████| 843/843 [00:09<00:00, 85.09batch/s, Loss = 0.4092, AUC = 98.79%] \n",
      "Epoch  20/30: 100%|██████████| 843/843 [00:10<00:00, 82.77batch/s, Loss = 0.4078, AUC = 98.79%] \n",
      "Epoch  21/30: 100%|██████████| 843/843 [00:10<00:00, 83.16batch/s, Loss = 0.4095, AUC = 98.80%] \n",
      "Epoch  22/30: 100%|██████████| 843/843 [00:10<00:00, 83.46batch/s, Loss = 0.3957, AUC = 98.87%] \n",
      "Epoch  23/30: 100%|██████████| 843/843 [00:10<00:00, 82.74batch/s, Loss = 0.3985, AUC = 98.84%] \n",
      "Epoch  24/30: 100%|██████████| 843/843 [00:09<00:00, 84.52batch/s, Loss = 0.3949, AUC = 98.87%] \n",
      "Epoch  25/30: 100%|██████████| 843/843 [00:10<00:00, 82.83batch/s, Loss = 0.3904, AUC = 98.88%] \n",
      "Epoch  26/30: 100%|██████████| 843/843 [00:10<00:00, 83.04batch/s, Loss = 0.3942, AUC = 98.86%] \n",
      "Epoch  27/30: 100%|██████████| 843/843 [00:10<00:00, 81.78batch/s, Loss = 0.3868, AUC = 98.90%] \n",
      "Epoch  28/30: 100%|██████████| 843/843 [00:10<00:00, 83.19batch/s, Loss = 0.3880, AUC = 98.91%] \n",
      "Epoch  29/30: 100%|██████████| 843/843 [00:09<00:00, 85.41batch/s, Loss = 0.3834, AUC = 98.92%] \n",
      "Epoch  30/30: 100%|██████████| 843/843 [00:10<00:00, 83.15batch/s, Loss = 0.3831, AUC = 98.91%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time = 338.45s, best validation AUC = 98.92% at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 156/156 [00:04<00:00, 38.56batch/s, Loss = 0.3841, AUC = 98.94%] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array(0.38410008, dtype=float32), 98.94037686108435, [], [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VisionTransformer(num_classes=10, patch_size=14, hidden_size=6, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=3,\n",
    "                          quantum_attn_circuit=get_circuit(), quantum_mlp_circuit=get_circuit())\n",
    "train_and_evaluate(model, mnist_train_dataloader, mnist_valid_dataloader, mnist_test_dataloader, num_classes=10, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
